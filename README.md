# EDISON-ComfyUI

<div align="center">

<img src="logo.png" alt="EDISON Logo" width="200"/>

**Your Complete Offline AI Platform**

*Enterprise-grade local LLM system with modern web UI, vision capabilities, RAG memory, and ComfyUI integration*

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Ubuntu 22.04+](https://img.shields.io/badge/ubuntu-22.04%2B-orange.svg)](https://ubuntu.com/)
[![CUDA 12+](https://img.shields.io/badge/CUDA-12%2B-green.svg)](https://developer.nvidia.com/cuda-downloads)

[Features](#features) â€¢ [Quick Start](#quick-start) â€¢ [Documentation](#documentation) â€¢ [Troubleshooting](#troubleshooting)

</div>

---

## ï¿½ What's New (v1.3.0)

### ğŸ§  **Intelligent Memory System**
- **Auto-Remember**: EDISON now automatically detects and stores important conversations without manual checkboxes! Personal info, preferences, goals, and reminders are stored automatically.
- **Explicit Recall**: Search your entire conversation history with natural commands like "recall our chat about Python" or "what did we discuss about movies?"
- **Cross-Chat Memory**: Access information from any previous conversation, not just the current one.

### ğŸ’¬ **Enhanced Conversation Intelligence**
- **Context Awareness**: EDISON maintains context across messages and understands follow-up questions using pronouns like "it", "that", "her", etc.
- **Smart Intent Detection**: 40+ patterns for accurate mode selection, including dedicated work mode detection for complex tasks.
- **Fact Extraction**: Automatically extracts and stores personal details, preferences, and important information for better recall.

### ğŸ–¥ï¸ **Complete Work Mode**
- **Task Breakdown**: Automatically breaks complex tasks into 3-7 actionable steps
- **Visual Progress**: See your task plan in a beautiful UI with numbered steps
- **Enhanced Responses**: Larger token limits (3072 vs 2048) for comprehensive task completion

### ğŸ“Š **Better User Experience**
- Removed manual "remember" checkbox - memory is now intelligent and automatic
- Improved conversation flow with better pronoun and reference understanding
- Enhanced RAG retrieval with multi-query expansion
- Cleaner UI with auto-memory indicator

**ğŸ“– Full Documentation**: See [AI_ENHANCEMENTS.md](AI_ENHANCEMENTS.md), [AUTO_REMEMBER.md](AUTO_REMEMBER.md), and [CONVERSATION_CONTEXT.md](CONVERSATION_CONTEXT.md)

---

## ï¿½ğŸ¯ Why EDISON?

**EDISON** (Enhanced Distributed Intelligence System for Offline Networks) is a production-ready, fully offline AI platform that brings enterprise-level capabilities to your local infrastructure:

- âœ… **100% Private** - All processing happens on your hardware
- âœ… **No API Costs** - One-time setup, unlimited usage
- âœ… **Multi-Modal** - Text, images, code, and vision understanding
- âœ… **Production Ready** - Systemd services, logging, monitoring
- âœ… **Multi-GPU Support** - Efficient tensor splitting across GPUs
- âœ… **Memory System** - RAG-powered long-term context retention

---

## âœ¨ Features

### ğŸš€ **Modern Web Interface**
- **Claude/ChatGPT-inspired UI** with real-time streaming responses
- **Conversation Management** - Save, load, and organize chat histories
- **File Upload Support** - Attach documents and images to conversations
- **Multiple AI Modes** - Chat, Deep Thinking, Reasoning, Code, Agent
- **Auto-Intent Detection** - Automatically selects optimal model and mode
- **Hardware Monitoring** - Real-time GPU, CPU, and memory stats
- **Work Mode** - Dedicated interface for complex multi-step tasks
- **Settings Panel** - Configure models, memory, and behavior

### ğŸ§  **Powerful AI Models**
- **Fast Mode (Qwen 2.5 14B)** - Instant responses for quick questions
- **Deep Mode (Qwen 2.5 72B)** - Comprehensive analysis and reasoning
- **Vision Model (LLaVA 1.6)** - Image understanding and description
- **Code Assistant** - Specialized for programming and technical tasks
- **Agent Mode** - Web search, tool use, and multi-step problem solving
- **Full GPU Acceleration** - CUDA-optimized inference with tensor splitting

### ğŸ¨ **Image Generation**
- **ComfyUI Integration** - Professional node-based workflow system
- **Custom EDISON Nodes** - Direct chat interface within ComfyUI
- **Workflow Library** - Pre-configured templates for common tasks
- **Real-time Generation** - Streaming progress updates

### ğŸ§© **Advanced Capabilities**
- **RAG Memory System** - Vector-based long-term context with Qdrant
- **Auto-Remember** ğŸ†• - Intelligently detects and stores important conversations without manual checkboxes
- **Explicit Recall** ğŸ†• - Search previous conversations with natural language ("recall our chat about X")
- **Conversation Context** ğŸ†• - Maintains context across messages, understands follow-up questions and pronouns
- **Enhanced Intent Detection** ğŸ†• - 40+ patterns for accurate mode selection and recall detection
- **Fact Extraction** ğŸ†• - Automatically extracts and stores personal information, preferences, and important details
- **Work Mode** ğŸ†• - Breaks down complex tasks into actionable steps with visual progress tracking
- **Web Search** - Agent mode with DuckDuckGo integration
- **File Processing** - Upload and analyze documents, images, and code
- **Intent Classification** - Optional Google Coral TPU acceleration
- **Multi-GPU Support** - Automatic load balancing across devices
- **Smart Prompting** - Context-aware system prompts per mode

### ğŸ”Œ **Enterprise Deployment**
- **One-Command Install** - Automated setup with dependency management
- **Systemd Services** - Auto-start on boot with crash recovery
- **Production Logging** - Structured logs with journalctl integration
- **Health Monitoring** - Endpoints for uptime and status checks
- **Network Access** - Secure LAN-accessible from any device
- **Zero Configuration** - Intelligent defaults with optional customization

---

## ğŸš€ Quick Start

### Prerequisites
- Ubuntu 22.04+ or Debian-based Linux
- NVIDIA GPU with 12GB+ VRAM (16GB+ recommended)
- CUDA 12.0+ drivers installed
- 100GB+ free disk space for models

### Installation (5 minutes)

```bash
# 1. Clone repository
git clone https://github.com/mikedattolo/EDISON-ComfyUI.git
cd EDISON-ComfyUI

# 2. Check system requirements
./scripts/check_system.sh

# 3. Run automated installation (installs all dependencies)
./scripts/setup_ubuntu.sh

# 4. Download AI models (~50GB)
python3 scripts/download_models.py

# 5. Install as system services (auto-start on boot)
sudo ./scripts/enable_services.sh

# 6. Access web interface
# Open browser: http://YOUR_SERVER_IP:8080
```

### What Gets Installed

| Service | Port | Description | Auto-Start |
|---------|------|-------------|------------|
| **edison-web** | 8080 | Modern web UI for chat | âœ… Yes |
| **edison-core** | 8811 | LLM inference API | âœ… Yes |
| **edison-coral** | 8808 | Intent classification | âœ… Yes |
| **edison-comfyui** | 8188 | ComfyUI image generation | âœ… Yes |

### First Steps

1. **Open Web UI** - Navigate to `http://YOUR_IP:8080`
2. **Try Chat Mode** - Ask: "What can you help me with?"
3. **Test Deep Mode** - Ask: "Explain quantum computing in detail"
4. **Upload Files** - Click ğŸ“ to attach documents or images
5. **Try Vision** - Upload an image and ask "What's in this image?"
6. **Enable Memory** - Toggle "Remember" to store conversations

---

## ğŸ“Š EDISON vs Cloud AI

| Feature | EDISON | ChatGPT/Claude | Local Alternatives |
|---------|--------|----------------|-------------------|
| **Privacy** | 100% offline | Cloud-based | Varies |
| **Cost** | One-time hardware | $20-200/month | Varies |
| **Latency** | <1s local | 1-5s network | <1s local |
| **Customization** | Full control | Limited | Limited |
| **Multi-modal** | Text + Vision + Image Gen | Text + Vision | Often separate |
| **Memory/RAG** | Built-in Qdrant | Token-limited | Often missing |
| **Production Ready** | Systemd services | N/A | Manual setup |
| **Multi-GPU** | Tensor splitting | N/A | Rarely supported |
| **Web Interface** | Modern, responsive | Excellent | Basic |
| **API Access** | OpenAI-compatible | Yes | Varies |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Web Browser (Any Device)           â”‚
â”‚            http://YOUR_IP:8080                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EDISON Web  â”‚   â”‚    ComfyUI      â”‚
â”‚   (8080)     â”‚   â”‚    (8188)       â”‚
â”‚  - Chat UI   â”‚   â”‚  - Node Editor  â”‚
â”‚  - File Up   â”‚   â”‚  - Workflows    â”‚
â”‚  - Settings  â”‚   â”‚  - Generation   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚           â”‚ EDISON Nodes    â”‚
       â”‚           â”‚ (Custom Nodes)  â”‚
       â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       EDISON Core (8811)            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   LLM Inference Engine      â”‚   â”‚
â”‚   â”‚  - Qwen 2.5 14B (Fast)      â”‚   â”‚
â”‚   â”‚  - Qwen 2.5 72B (Deep)      â”‚   â”‚
â”‚   â”‚  - LLaVA 1.6 (Vision)       â”‚   â”‚
â”‚   â”‚  - llama-cpp-python + CUDA  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   RAG System (Qdrant)       â”‚   â”‚
â”‚   â”‚  - Vector embeddings        â”‚   â”‚
â”‚   â”‚  - Conversation memory      â”‚   â”‚
â”‚   â”‚  - Document storage         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   Tool System               â”‚   â”‚
â”‚   â”‚  - Web Search (DuckDuckGo)  â”‚   â”‚
â”‚   â”‚  - Code execution           â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EDISON Coral (8808)                â”‚
â”‚   Intent Classification              â”‚
â”‚   - Auto mode detection             â”‚
â”‚   - Coral TPU acceleration (opt)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» System Requirements

### Minimum Configuration
| Component | Requirement | Notes |
|-----------|-------------|-------|
| **OS** | Ubuntu 22.04+ | Debian-based Linux |
| **CPU** | 8+ cores | Intel/AMD x86_64 |
| **RAM** | 32GB | For 14B models |
| **Storage** | 100GB free | For models + system |
| **GPU** | 12GB VRAM | RTX 3060 12GB minimum |
| **Python** | 3.9+ | Installed by setup script |

### Recommended Configuration
| Component | Requirement | Notes |
|-----------|-------------|-------|
| **RAM** | 64GB+ | For 72B deep model |
| **Storage** | 200GB+ NVMe | Faster model loading |
| **GPU** | 16GB+ VRAM | RTX 4080/4090/A5000 |
| **CUDA** | 12.0+ | Latest drivers |
| **Network** | Gigabit LAN | For remote access |
| **Optional** | Coral M.2 TPU | Intent classification |

### Multi-GPU Support
EDISON automatically splits models across multiple GPUs:
- **3x GPU Setup**: 50% / 25% / 25% tensor split
- **2x GPU Setup**: 60% / 40% tensor split  
- **1x GPU**: Full model on single GPU

---

## Installation

### Automated Installation (Recommended)

```bash
# Clone repository
git clone https://github.com/mikedattolo/EDISON-ComfyUI.git
cd EDISON-ComfyUI

# Run system check
./scripts/check_system.sh

# Install everything
./scripts/setup_ubuntu.sh

# Download models
python3 scripts/download_models.py

# Deploy as services
sudo ./scripts/enable_services.sh
```

### Services Installed

After installation, the following services will be running:

| Service | Port | Description |
|---------|------|-------------|
| `edison-web` | 8080 | Modern web UI for chat interface |
| `edison-core` | 8811 | Main AI service with LLM inference |
| `edison-coral` | 8808 | Intent classification service |
| `edison-comfyui` | 8188 | ComfyUI for image generation |

All services auto-start on boot and are accessible from network.

---

## Usage

### Web UI

Open your browser to **http://YOUR_IP:8080**

Features:
- ğŸ’¬ **Chat modes**: Auto, Chat (14B), Deep (72B), Code, Agent
- ğŸ“ **Conversation history** saved in browser
- âš™ï¸ **Settings panel** for configuration
- ğŸ” **System status** monitoring
- ğŸ¨ **Modern dark theme**

### API Usage

#### Chat Endpoint

```bash
curl -X POST http://YOUR_IP:8811/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explain quantum computing",
    "mode": "deep",
    "remember": true
  }'
```

#### Intent Classification

```bash
curl -X POST http://YOUR_IP:8808/intent \
  -H "Content-Type: application/json" \
  -d '{"text": "Generate an image of a sunset"}'
```

#### Health Check

```bash
curl http://YOUR_IP:8811/health
curl http://YOUR_IP:8080/health
```

### ComfyUI Integration

1. Open ComfyUI at **http://YOUR_IP:8188**
2. Right-click â†’ **Add Node** â†’ **EDISON** â†’ **EDISON Chat**
3. Configure:
   - **text**: Your message
   - **mode**: auto, chat, deep, code, or agent
   - **remember**: true/false
   - **timeout_seconds**: 120 (default)

### Modes Explained

| Mode | Model | Use Case |
|------|-------|----------|
| **Auto** | Detected | Automatically selects best mode based on intent |
| **Chat** | 14B | Quick responses, casual conversation |
| **Deep** | 72B | Detailed analysis, complex reasoning |
| **Code** | 72B | Programming assistance, debugging |
| **Agent** | 72B | Tool-using, multi-step tasks |

---

## Service Management

```bash
# Check status
sudo systemctl status edison-core edison-web

# Restart services
sudo systemctl restart edison-core

# View logs
sudo journalctl -u edison-core -f

# Stop services
sudo systemctl stop edison-core edison-web

# Disable auto-start
sudo systemctl disable edison-core
```

---

## Documentation

ğŸ“š **Comprehensive guides available:**

- **[INSTALL.md](INSTALL.md)** - Detailed installation guide with all options
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - Solutions to common issues
- **[COPILOT_SPEC.md](COPILOT_SPEC.md)** - Original specification
- **[IMPLEMENTATION_COMPLETE.md](IMPLEMENTATION_COMPLETE.md)** - Implementation notes

---

## Troubleshooting

### Common Issues

**âŒ Disk space full**
```bash
# Expand LVM partition
sudo lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv
sudo resize2fs /dev/ubuntu-vg/ubuntu-lv
```

**âŒ Python 3.12 + Coral TPU**
- Coral `pycoral` library incompatible with Python 3.12
- System automatically uses heuristic classification instead
- Or use separate Python 3.11 venv for coral service

**âŒ Service won't start**
```bash
# Check logs for specific error
sudo journalctl -u edison-core -n 50

# Common fix: Ensure models are downloaded
ls -lh /opt/edison/models/llm/
```

**âŒ Can't access from network**
```bash
# Check firewall
sudo ufw allow 8080/tcp
sudo ufw allow 8811/tcp
sudo ufw allow 8188/tcp
```

**âŒ Coral TPU kernel module errors**
```bash
# Automated fix for kernel 6.8+ API changes
sudo ./scripts/fix_coral_tpu.sh
sudo reboot
```

**âŒ GPU not working**
```bash
# Verify CUDA
nvidia-smi
nvcc --version

# Check PyTorch GPU support
python3 -c "import torch; print(torch.cuda.is_available())"
```

See **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** for detailed solutions.

---

## Updating

```bash
cd /workspaces/EDISON-ComfyUI
git pull
source .venv/bin/activate
pip install -r requirements.txt --upgrade

# If services installed:
sudo ./scripts/enable_services.sh
sudo systemctl daemon-reload
sudo systemctl restart edison-core edison-web edison-comfyui
```

---

## Uninstallation

```bash
# Stop and remove services
sudo systemctl stop edison-coral edison-core edison-web edison-comfyui
sudo systemctl disable edison-coral edison-core edison-web edison-comfyui
sudo rm /etc/systemd/system/edison-*.service
sudo systemctl daemon-reload

# Remove installation
sudo rm -rf /opt/edison

# Remove user (optional)
sudo userdel edison
```

---

## Development

### Local Development Mode

Run services locally without systemd:

```bash
# Terminal 1: Coral service
source .venv/bin/activate
python -m uvicorn services.edison_coral.service:app --host 0.0.0.0 --port 8808

# Terminal 2: Core service
source .venv/bin/activate
python -m uvicorn services.edison_core.app:app --host 0.0.0.0 --port 8811

# Terminal 3: Web UI
source .venv/bin/activate
python -m uvicorn services.edison_web.service:app --host 0.0.0.0 --port 8080

# Terminal 4: ComfyUI
source .venv/bin/activate
cd ComfyUI
python main.py --listen 0.0.0.0 --port 8188
```

### Project Structure

```
EDISON-ComfyUI/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ edison_core/          # Main AI service
â”‚   â”‚   â”œâ”€â”€ app.py           # FastAPI app with LLM inference
â”‚   â”‚   â”œâ”€â”€ prompts.py       # System prompts
â”‚   â”‚   â”œâ”€â”€ rag.py           # RAG with Qdrant
â”‚   â”‚   â””â”€â”€ tools.py         # Agent tools
â”‚   â”œâ”€â”€ edison_coral/        # Intent classification
â”‚   â”‚   â””â”€â”€ service.py
â”‚   â”œâ”€â”€ edison_web/          # Web UI service
â”‚   â”‚   â””â”€â”€ service.py
â”‚   â””â”€â”€ systemd/             # Service files
â”œâ”€â”€ web/                     # Web UI frontend
â”‚   â”œâ”€â”€ index.html          # Main HTML
â”‚   â”œâ”€â”€ styles.css          # Modern styling
â”‚   â””â”€â”€ app.js              # Client-side logic
â”œâ”€â”€ ComfyUI/
â”‚   â””â”€â”€ custom_nodes/
â”‚       â””â”€â”€ edison_nodes/    # EDISON custom nodes
â”œâ”€â”€ scripts/                 # Installation scripts
â”‚   â”œâ”€â”€ check_system.sh     # System requirements checker
â”‚   â”œâ”€â”€ setup_ubuntu.sh     # Main setup script
â”‚   â”œâ”€â”€ fix_coral_tpu.sh    # Coral TPU auto-fixer
â”‚   â”œâ”€â”€ download_models.py  # Model downloader
â”‚   â””â”€â”€ enable_services.sh  # Service installer
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ edison.yaml         # Main configuration
â”‚   â””â”€â”€ gpu_map.yaml        # GPU assignments
â””â”€â”€ models/                  # Model storage
    â”œâ”€â”€ llm/                # GGUF models
    â”œâ”€â”€ qdrant/             # Vector database
    â””â”€â”€ embeddings/         # Sentence transformers
```

---

## Performance Tips

### For 14B Model Only
If you only have 32GB RAM, use only the fast model:
```yaml
# config/edison.yaml
edison:
  core:
    fast_model: "qwen2.5-14b-instruct-q4_k_m.gguf"
    deep_model: "qwen2.5-14b-instruct-q4_k_m.gguf"  # Same as fast
```

### GPU Optimization
```python
# services/edison_core/app.py
llm_fast = Llama(
    model_path=str(fast_model_path),
    n_ctx=4096,
    n_gpu_layers=-1,      # -1 = offload all layers to GPU
    n_threads=8,          # CPU threads for non-GPU work
    verbose=False
)
```

### Multiple GPUs
```bash
# Set in systemd service
Environment="CUDA_VISIBLE_DEVICES=0,1,2"
```

---

## Security Considerations

### Network Exposure
By default, all services bind to `0.0.0.0` for network access. For localhost-only:

```bash
# Edit service files
sudo nano /etc/systemd/system/edison-web.service
# Change: --host 0.0.0.0 to --host 127.0.0.1
sudo systemctl daemon-reload
sudo systemctl restart edison-web
```

### Firewall
```bash
# Allow specific IPs only
sudo ufw default deny incoming
sudo ufw allow from 192.168.1.0/24 to any port 8080
sudo ufw allow from 192.168.1.0/24 to any port 8811
sudo ufw enable
```

---

## Known Issues

### Python 3.12 + Coral TPU
- **Issue**: `pycoral` library not compatible with Python 3.12
- **Status**: System automatically uses heuristic classification
- **Workaround**: Use separate Python 3.11 venv for coral service
- **Tracking**: Waiting for pycoral Python 3.12 support

### RTX 5060 Ti (Blackwell)
- **Issue**: PyTorch 2.5.1 doesn't support compute capability 12.0
- **Status**: GPU falls back to CPU
- **Workaround**: Use other GPUs or wait for PyTorch 2.6+
- **Tracking**: PyTorch 2.6 will add Blackwell support

### Coral TPU Kernel 6.8+
- **Issue**: gasket driver incompatible with kernel 6.8+ API changes
- **Status**: âœ… Fixed with automated patcher
- **Solution**: Run `sudo ./scripts/fix_coral_tpu.sh`

---

## Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

Areas for contribution:
- Additional model support
- UI improvements
- Documentation
- Bug fixes
- Performance optimizations

---

## License

MIT License - see [LICENSE](LICENSE) file for details

---

## Acknowledgments

- **llama-cpp-python** - Fast LLM inference
- **ComfyUI** - Node-based image generation
- **Qwen** - Excellent open-source models
- **Qdrant** - Vector database
- **FastAPI** - Modern web framework
- **Google Coral** - Edge TPU acceleration

---

## Support

- ğŸ“– [Installation Guide](INSTALL.md)
- ğŸ”§ [Troubleshooting Guide](TROUBLESHOOTING.md)
- ğŸ› [Issue Tracker](https://github.com/mikedattolo/EDISON-ComfyUI/issues)
- ğŸ’¬ [Discussions](https://github.com/mikedattolo/EDISON-ComfyUI/discussions)

---

<div align="center">

**Made with â¤ï¸ for the open-source AI community**

[â¬† Back to Top](#edison-comfyui)

</div>

# Activate venv
source .venv/bin/activate

# Terminal 1 - Coral service
python -m uvicorn services.edison_coral.service:app --host 127.0.0.1 --port 8808

# Terminal 2 - Core service
python -m uvicorn services.edison_core.app:app --host 127.0.0.1 --port 8811

# Terminal 3 - ComfyUI
cd ComfyUI
python main.py --listen 0.0.0.0 --port 8188
```

## Configuration

Edit `/opt/edison/config/edison.yaml`:

```yaml
edison:
  core:
    host: "127.0.0.1"
    port: 8811
    models_path: "models/llm"
    fast_model: "qwen2.5-14b-instruct-q4_k_m.gguf"
    deep_model: "qwen2.5-72b-instruct-q4_k_m.gguf"
  
  coral:
    host: "127.0.0.1"
    port: 8808
```

Restart services after changes:
```bash
sudo systemctl restart edison-core edison-coral
```

## Project Structure

```
EDISON-ComfyUI/
â”œâ”€â”€ config/              # Configuration files
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ edison_core/     # LLM service (FastAPI)
â”‚   â”œâ”€â”€ edison_coral/    # Intent service (FastAPI)
â”‚   â””â”€â”€ systemd/         # Service unit files
â”œâ”€â”€ scripts/             # Setup and maintenance scripts
â”œâ”€â”€ models/              # Model storage
â”‚   â”œâ”€â”€ llm/            # GGUF models
â”‚   â”œâ”€â”€ qdrant/         # Vector DB
â”‚   â””â”€â”€ coral/          # Edge TPU models
â””â”€â”€ ComfyUI/
    â””â”€â”€ custom_nodes/
        â””â”€â”€ edison_nodes/  # EDISON custom node
```

## License

See LICENSE file.

## Support

For issues, please check:
1. Run `bash scripts/doctor.sh`
2. Check service logs
3. Review COPILOT_SPEC.md for detailed requirements