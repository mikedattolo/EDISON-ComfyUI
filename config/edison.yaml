# EDISON Configuration

edison:
  core:
    host: "127.0.0.1"
    port: 8811
    models_path: "models/llm"
    fast_model: "qwen2.5-14b-instruct-q4_k_m.gguf"
    medium_model: "qwen2.5-coder-32b-instruct-q4_k_m.gguf"
    deep_model: "qwen2.5-72b-instruct-q4_k_m.gguf"
    reasoning_model: "qwen2.5-coder-32b-instruct-q4_k_m.gguf"
    vision_model: "llava-v1.6-mistral-7b-q4_k_m.gguf"  # Best available VLM (default)
    vision_clip: "llava-v1.6-mistral-7b-mmproj-q4_0.gguf"  # CLIP projector for vision
    vision_code_model: "Qwen2-VL-7B-Instruct-Q4_K_M.gguf"
    vision_code_clip: "mmproj-Qwen2-VL-7B-Instruct-f16.gguf"
    # Context window settings
    n_ctx: 4096
    context_window: 131072
    fast_n_ctx: 4096
    medium_n_ctx: 4096
    deep_n_ctx: 8192
    reasoning_n_ctx: 8192
    vision_n_ctx: 2048
    vision_code_n_ctx: 4096
    # GPU split and attention settings
    tensor_split: [0.55, 0.30, 0.15]
    # Per-model GPU offload (lower values reduce VRAM usage)
    n_gpu_layers: -1
    deep_n_gpu_layers: 35
    reasoning_n_gpu_layers: 24
    vision_n_gpu_layers: 20
    vision_code_n_gpu_layers: 16
    use_flash_attn: false
    flash_attn_recompute: false

  orchestration:
    enabled: true
    default_mode: "instant"
    swarm_max_agents: 4
    tool_access: true

  agent_modes:
    instant:
      max_tokens: 1024
      reasoning: "light"
    thinking:
      max_tokens: 4096
      reasoning: "deep"
    agent:
      tools: true
    swarm:
      tools: true
      parallel: true
    work:
      max_tokens: 3072
      tools: true
      search: true
      artifacts: true
      max_steps: 7
      step_by_step: true
      model: "deep"

  projects:
    root: "outputs"
    sandbox:
      docker_image: "python:3.11-slim"
      memory_limit: "1g"
      cpu_quota: 200000

  artifacts:
    root: "outputs"
    formats:
      - "md"
      - "pdf"
      - "docx"
      - "json"

  safety:
    thresholds:
      auto_block: 0.9
      require_confirm: 0.5

  memory:
    global_scope: "global"
    project_scopes: true
  
  coral:
    enabled: true
    host: "127.0.0.1"
    port: 8808
    device: "/dev/apex_0"
    model_path: "models/coral/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite"
  
  comfyui:
    host: "127.0.0.1"
    port: 8188
    auto_start: true
  
  video:
    default_frames: 16
    default_fps: 8
    default_width: 512
    default_height: 512
    default_steps: 20
    # Preferred backend: cogvideox, animatediff, wan21, framebased (auto-detected)
    # preferred_backend: "auto"

  music:
    model_size: "medium"       # small (~4GB VRAM), medium (~8GB), large (~16GB), melody (~8GB)
    default_duration: 15       # seconds
    max_duration: 60           # max generation length

  logging:
    level: "INFO"
    file: "logs/edison.log"

  vllm:
    enabled: false
    host: "127.0.0.1"
    port: 8822
    tensor_parallel_size: 3
    gpu_memory_utilization: 0.90

  voice:
    enabled: false
    host: "127.0.0.1"
    port: 8809
